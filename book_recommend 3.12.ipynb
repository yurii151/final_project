{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e69bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from collections import Counter\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1d0c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "file_path = 'books.csv'\n",
    "df = pd.read_csv(file_path, error_bad_lines = False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcd82df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = [\"bookID\", \"title\", \"authors\", \"average_rating\", \n",
    "#              \"isbn\", \"isbn13\", \"language_code\", \"num_pages\",\n",
    "#              \"ratings_count\", \"text_reviews_count\", \"publication_date\", \"publisher\"]\n",
    "# target = [\"recommend\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff9f3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the target column values to 1 and 0 based on their values\n",
    "# if average rating is less than 3.5 = 0\n",
    "# if average rating is more than 3.5 = 1\n",
    "df['recommend'] = np.where((df['average_rating'] >= 3.50), 1, 0) \n",
    "\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58c9d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6672e75b",
   "metadata": {},
   "source": [
    "split and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d30957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our features\n",
    "X = pd.get_dummies(df, columns=[\"bookID\", \"title\", \"authors\", \"average_rating\", \n",
    "           \"isbn\", \"isbn13\", \"language_code\", \"  num_pages\",\n",
    "           \"ratings_count\", \"text_reviews_count\", \"publication_date\", \"publisher\"]).drop_first=True\n",
    "#pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cd5446",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=\"recommend\")\n",
    "y = df[\"recommend\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12be16ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a573577",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d657bb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4c394e",
   "metadata": {},
   "source": [
    "from challenge 17: oversampling\n",
    "View the count of the target classes using Counter from the collections library.\n",
    "Use the resampled data to train a logistic regression model.\n",
    "Calculate the balanced accuracy score from sklearn.metrics.\n",
    "Print the confusion matrix from sklearn.metrics.\n",
    "Generate a classication report using the imbalanced_classification_report from imbalanced-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee62e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the training data with the RandomOversampler\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "## instantiate the model\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "## resample the targets\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c58c8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "\n",
    "## fit\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3ab241",
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate predictions\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5411150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5308f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "## calculate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb358e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_df = pd.DataFrame(\n",
    "    cm, index=['Actual 1', 'Actual 0'], columns=['Predicted 1', 'Predicted 0'])\n",
    "cm_df\n",
    "\n",
    "####---##### need to double check that the results match the confusion matrix output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2688ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
